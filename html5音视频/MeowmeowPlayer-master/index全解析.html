<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Document</title>
<style type="text/css">
#cas{
  position: absolute;
  left:0;top:0;bottom: 0;right: 0;
  margin: auto;
  border: 1px solid;
}
</style>
</head>
<body>
  <input type="file" name="" id="music" />
  <canvas id="cas" width="1000" height="540"></canvas>
  <script type="text/javascript" charset="utf-8">
    var music = document.getElementById("music"),
		canvas = document.getElementById("cas"),
		ctx=canvas.getContext("2d");
    window.AudioContext= window.AudioContext||window.webkitAudioContext||window.mozAudioContext||window.msAudioContext;
	window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame;
    var AC = new AudioContext();
    
	//监听是否有文件被选中
    music.onchange = function(){
      //这里判断一下文件长度可以确定用户是否真的选择了文件，如果点了取消则文件长度为0
      if(music.files.length!==0){
        changeBuffer(music.files[0]);
      }
    }
    

	//文件得到了，但首先需要将获取的文件转换为ArrayBuffer格式，才能够传递给AudioContext进行解码
	function changeBuffer(file){
	  //实例化一个FileReader用于读取文件
      var fr = new FileReader();
	  //文件读取完后调用此函数
      fr.onload = function(e){
		//这是读取成功得到的结果ArrayBuffer数据
        var fileResult = e.target.result;
		/*decodeAudioData方法有三个参数：第一个是音频ArrayBuffer对象，第二个是成功解码完毕后的回调，第三个是解码失败后的回调*/
        AC.decodeAudioData(fileResult , function(buffer){//解码成功则调用此函数，参数buffer为解码后得到的结果
          playMusic(buffer)
        }, function(e){//这个是解码失败会调用的函数
          console.log(e)
          alert("文件解码失败")
        })
      }
      //将上一步获取的文件传递给FileReader从而将其读取为ArrayBuffer格式
	  fr.readAsArrayBuffer(file);
    }
    
	//声明一个分析器,用于获取频谱能量信息
    var analyser;
	//播放音乐
    function playMusic(buffer){
	  //实例化一个AudioBufferSource对象
      var absn = AC.createBufferSource();
	  //创建一个分析器
      analyser = AC.createAnalyser();
	   /*为了将音频在播放前截取，所以要把analyser插在audioBufferSouceNode与audioContext.destination之间。可以这样：
	   audioBufferSouceNode.connect(analyser);
	   analyser.connect(audioContext.destination);
	   */

	  //将音频跟分析器连接起来
      absn.connect(analyser);
	  //将音频连接到扬声器上
      absn.connect(AC.destination);
	  /*AudioBufferSource对象的属性有五个。分别是：buffer、playbackRate、loop、loopstart和loopend，buffer自然就是音频buffer数据，playbackRate是渲染音频流的速度，其默认值是1。loop则是播放循环属性，默认为false，如果设为true则会循环播放音频。loopstart和loopend则是循环开始和结束的时间段，以秒为单位，默认值均为0，只有当loop的值为true的时候这两个属性才会起效*/

	  //把音频文件的内容装进了AudioContext
      absn.buffer = buffer;
      absn.loop = true;
      absn.start(0);
	  //绘制音频数据
      animate()
    }
    
    function animate(){
      //下面的代码可以从analyser中得到此刻的音频中各频率的能量值
      var array = new Uint8Array(analyser.frequencyBinCount);
	  /*频域数据的获取接口。可以通过getByteFrequencyData方法来获取频域数据，同时域数据的获取一样，使用一个定长的缓冲区来存放获取的数据。这个长度可以在frequencyBinCount属性中找到。*/
      analyser.getByteFrequencyData(array);
      ctx.clearRect(0,0,canvas.width,canvas.height);
      for(var i=0;i<array.length;i+=10){
		//createLinearGradient(x0:渐变开始点的x坐标,y0:渐变开始点的y坐标,x1:渐变结束点的x坐标,y1:渐变结束点的y坐标);
		var clg=ctx.createLinearGradient(0,0,170,0);
		grd.addColorStop(0,"black");
		grd.addColorStop(1,"white");
		//fillRect(x:矩形左上角的x坐标, y:矩形左上角的y坐标,width:矩形的宽度，以像素计,height:矩形的高度，以像素计)
        ctx.fillRect(i,canvas.height-array[i] , 10 , array[i]); 
        ctx.strokeStyle = "#FFF"
        ctx.strokeRect(i,canvas.height-array[i] , 10 , array[i]);
      }
      requestAnimationFrame(animate);
    };

	/*我们的画布即Canvas宽800px,同时我们设定柱条宽10px , 柱与柱间间隔为2px，所以得到meterNum为总共可以画的柱条数。再用数组总长度除以这个数目就得到采样的步长，即在遍历array时每隔step这么长一段我们从数组中取一个值出来画，这个值为array[i*step]。这样就均匀地取出meterNum个值，从而正确地反应了原来频谱图的形状。*/
	function drawSpectrum(analyser) {
		var canvas = document.getElementById('canvas'),
			cwidth = canvas.width,
			cheight = canvas.height - 2,
			meterWidth = 10, //频谱条宽度
			gap = 2, //频谱条间距
			capHeight = 2,
			capStyle = '#fff',
			meterNum = 800 / (10 + 2), //频谱条数量
			capYPositionArray = []; //将上一画面各帽头的位置保存到这个数组
		ctx = canvas.getContext('2d'),
		gradient = ctx.createLinearGradient(0, 0, 0, 300);
		gradient.addColorStop(1, '#0f0');
		gradient.addColorStop(0.5, '#ff0');
		gradient.addColorStop(0, '#f00');
		var drawMeter = function() {
			var array = new Uint8Array(analyser.frequencyBinCount);
			analyser.getByteFrequencyData(array);
			var step = Math.round(array.length / meterNum); //计算采样步长
			ctx.clearRect(0, 0, cwidth, cheight);
			for (var i = 0; i < meterNum; i++) {
				var value = array[i * step]; //获取当前能量值
				if (capYPositionArray.length < Math.round(meterNum)) {
					capYPositionArray.push(value); //初始化保存帽头位置的数组，将第一个画面的数据压入其中
				};
				ctx.fillStyle = capStyle;
				
				/*再实现一下柱条上方缓慢降落的帽头。
				原理也很简单，就是在绘制柱条的同时在同一X轴的位置再绘制一个短的柱条，并且其开始和结束位置都要比频谱中的柱条高。难的地方便是如何实现缓慢降落。
				首先要搞清楚的一点是，我们拿一根柱条来说明问题，当此刻柱条高度高于前一时刻时，我们看到的是往上冲的一根频谱，所以这时帽头是紧贴着正文柱条的，这个好画。考虑相反的情况，当此刻高度要低于前一时刻的高度时，下方柱条是立即缩下去的，同时我们需要记住上一时刻帽头的高度位置，此刻画的时候就按照前一时刻的位置将Y-1来画。如果下一时刻频谱柱条还是没有超过帽头的位置，继续让它下降，Y-1画出帽头。
				通过上面的分析，所以我们在每次画频谱的时刻，需要将此刻频谱及帽头的Y值（即垂直方向的位置）记到一个循环外的变量中，在下次绘制的时刻从这个变量中读取，将此刻的值与变量中保存的上一刻的值进行比较，然后按照上面的分析作图*/

				//开始绘制帽头
				if (value < capYPositionArray[i]) { //如果当前值小于之前值
					ctx.fillRect(i * 12, cheight - (--capYPositionArray[i]), meterWidth, capHeight); //则使用前一次保存的值来绘制帽头
				} else {
					ctx.fillRect(i * 12, cheight - value, meterWidth, capHeight); //否则使用当前值直接绘制
					capYPositionArray[i] = value;
				};
				//开始绘制频谱条
				ctx.fillStyle = gradient;
				ctx.fillRect(i * 12, cheight - value + capHeight, meterWidth, cheight);
			}
			/*但上面绘制的仅仅是某一刻的频谱，要让整个画面动起来，我们需要不断更新画面，window.requestAnimationFrame()正好提供了更新画面得到动画效果的功能*/
			requestAnimationFrame(drawMeter);
		}
		requestAnimationFrame(drawMeter);
		/*requestAnimationFrame:这个方法原理其实也就跟setTimeout/setInterval差不多，通过递归调用同一方法来不断更新画面以达到动起来的效果，但它优于setTimeout/setInterval的地方在于它是由浏览器专门为动画提供的API，在运行时浏览器会自动优化方法的调用，并且如果页面不是激活状态下的话，动画会自动暂停，有效节省了CPU开销。可以直接调用requestAnimationFrame(callback)//callback为回调函数*/
	};

  </script>
</body>
</html>